{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IESTI01_List_2 - TF_Exploring_DNN_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreNasci/TinyML/blob/main/IESTI01_List_3_TF_Exploring_DNN_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eqGXEvA3hyv"
      },
      "source": [
        "# Exploring DNN learning with TensorFlow\n",
        "\n",
        "In this assignment we'll dive a little deeper with a series of hands on exercises to better understand DNN learning with Tensorflow. Remember that I could be asking you questions about this assignment in the Quiz!\n",
        "\n",
        "We will work with the [Fashion MNIST Dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data). This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. \n",
        "\n",
        "We will define a possible model for you start working:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load in fashion MNIST\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Define the base model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)), \n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# 512 neurônios na camada 2 (dense layer), com f_ativ 'relu'\n",
        "# 10 neurônios na camada de saída, com f_ativ 'softmax'\n",
        "# ML Supervisionado: possui labels/tutor\n",
        "# DNN: Dense Neural Network ou Feed Foward NN: todos os neurônios da camada\n",
        "# anterior se conectam com todos os neurônios da camada seguinte\n",
        "# Classificador: gera uma predição em classe (10 classes = 10 neurônios na\n",
        "# camada se saída + f_ativ na saída)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZgtU7j3hy6"
      },
      "source": [
        "Neural Networks learn the best when the data is scaled / normalized to fall in a constant range. One practitioners often use is the range [0,1]. How might you do this to the training and test images used here?\n",
        "\n",
        "*A hint: these images are saved in the standard [RGB](https://www.rapidtables.com/web/color/RGB_Color.html) format*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R:** We can normalize the data to [0,1] range by dividing it by 255."
      ],
      "metadata": {
        "id": "NCqq4BdAG1Mj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlb9CPM3hy7"
      },
      "source": [
        "# Normalizando os valores de cada pixel para escala [0-1]\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqalGey3hy7"
      },
      "source": [
        "Using these improved images lets compile our model using an adaptive optimizer to learn faster (`Adam`) and a categorical loss function (`sparse_categorical_crossentropy`) to differentiate between the the various classes we are trying to classify. Since this is a very simple dataset we will only train for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpCFRc1L3hy7",
        "outputId": "f6e95e9e-d332-4bc6-c12a-1099cde7d747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']) \n",
        "# metrics = metrics to be evaluated by the model during\n",
        "# training and testing (evaluated = avaliado)\n",
        "\n",
        "# fit (treina) the model to the training data\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 21s 10ms/step - loss: 0.4743 - accuracy: 0.8302\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3603 - accuracy: 0.8689\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3214 - accuracy: 0.8812\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3001 - accuracy: 0.8893\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2803 - accuracy: 0.8954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f135e3566a0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model on the test data\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "AAZVqOzg1xPG",
        "outputId": "a27d2826-e774-405b-fcee-98a843eb2538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.331129252910614, 0.8817999958992004]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJMsvSB-1UY"
      },
      "source": [
        "Once it's done training -- you should see **an accuracy value at the end of the final epoch**. It might look something like 0.8648. This tells you that your neural network is about 86% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 86% of the time. But how would it work with unseen data? That's why we have the test images. We can call ```model.evaluate```, and pass in the two sets, and it will report back the loss for each. This should reach about .8747 or thereabouts, showing about 87% accuracy. Not Bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rquQqIx4AaGR"
      },
      "source": [
        "But what did it actually learn? If we inference on the model using ```model.predict``` we get out the following list of values. **What does it represent?**\n",
        "\n",
        "*A hint: trying running ```print(test_labels[0])```*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R:** It represents the predictions for each image in the test data subset. Each prediction is in a different index."
      ],
      "metadata": {
        "id": "w1i5wvBvHkRF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEIki0z_hAD",
        "outputId": "be914851-3629-4a72-cf01-7c5f42f19cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Inference on the model\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0]) # this is the prediction for test_images[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "[1.9207448e-06 7.0294504e-08 1.2305502e-08 4.7650538e-08 3.1719107e-08 1.1690886e-02 1.2238793e-06 2.7363410e-02 5.5423106e-07 9.6094185e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0]) # this is the label for test_images[0]"
      ],
      "metadata": {
        "id": "CBO2VqSZ2D5q",
        "outputId": "300a6485-80fd-49b0-b931-29f7da99e80b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6"
      },
      "source": [
        "Let's now look at the layers in your model. What happens if you double the number of neurons in the dense layer. What different results do you get for loss, training time etc? Why do you think that's the case? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R:** I expected a longer training time and slightly worse results because of the increase in the number of parameters. However, despite the longer time of trainnig, we achieved a slighly better accuracy. "
      ],
      "metadata": {
        "id": "Gu9Dr2JHIIOZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZSwV5UObQP",
        "outputId": "a5f900c8-e425-4853-a194-b7e5dcdb7b2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "NUMBER_OF_NEURONS = 512 * 2\n",
        "\n",
        "# define the new model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(NUMBER_OF_NEURONS, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# compile fit and evaluate the model again\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.4735 - accuracy: 0.8300\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3574 - accuracy: 0.8696\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3177 - accuracy: 0.8821\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.2977 - accuracy: 0.8891\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2772 - accuracy: 0.8961\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3437 - accuracy: 0.8725\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34367525577545166, 0.8725000023841858]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF"
      },
      "source": [
        "Consider the effects of additional layers in the network instead of simply more neurons to the same layer. First update the model to add an additional dense layer into the model between the two existing Dense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1bQi-mh3hy-"
      },
      "source": [
        "# Uma nova camada com 20 neurônios\n",
        "YOUR_NEW_LAYER = tf.keras.layers.Dense(20, activation=tf.nn.relu)\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    YOUR_NEW_LAYER,\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6X2d2S13hy-"
      },
      "source": [
        "Lets then compile, fit, and evaluate our model. What happens to the error? How does this compare to the original model and the model with double the number of neurons?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R:** Both error and accuracy are worse than the original model. However, we achieved better accuracy and smaller error than the model with twice the number of neurons. "
      ],
      "metadata": {
        "id": "w9iTlpvWJg5u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "outputId": "55edc1d6-6608-49b9-95c3-1f3946706a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# compile fit and evaluate the model again\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.5234 - accuracy: 0.8188\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3694 - accuracy: 0.8657\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3340 - accuracy: 0.8779\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3088 - accuracy: 0.8854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2893 - accuracy: 0.8939\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3417714536190033, 0.8797000050544739]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "Before you trained, you normalized the data. What would be the impact of removing that? To see it for yourself fill in the following lines of code to get a non-normalized set of data and then re-fit and evaluate the model using this data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R:** I expected a slightly worse results. However, it surprises me that the non-normalized dataset gives us such a poor result regarding accuracy and error."
      ],
      "metadata": {
        "id": "JFSctvGnKSE5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "outputId": "84ac83f6-78ce-4fb4-a966-e8ce289fa2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get new non-normalized mnist data\n",
        "training_images_non = training_images * 255\n",
        "test_images_non = test_images * 255\n",
        "\n",
        "# re-compile, re-fit and re-evaluate\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    YOUR_NEW_LAYER,\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images_non, training_labels, epochs=5)\n",
        "model.evaluate(test_images_non, test_labels)\n",
        "classifications = model.predict(test_images_non)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 3.3536 - accuracy: 0.1057\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 2.3028 - accuracy: 0.0984\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 2.3028 - accuracy: 0.0988\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 2.3028 - accuracy: 0.0983\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1000\n",
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    }
  ]
}